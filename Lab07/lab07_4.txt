Exercise 7.4
a. Submit solutions to tasks 1â€“5.
task 1
The min value of Housing_median_age in training and validation are 1.0. In common sense, it does not make sense to have a median age of 1.0. 
Also, the max values for total_rooms, total_beadrooms, population, households and rooms_per_person are generally too large for each mean value. 
Moreover, the difference between max and 75% of those values are 6 to 24 times. This big difference can make errors in the data.
task 2
Training data includes data for all California areas, but validation data only includes data for northern California from around San Jose. 
Therefore, since the two data are not equally distributed, the training data and validation data are incorrect, and the data are needed to reorder/shuffle.
task 3
The data was not properly mixed because the part to reorder/shuffle the data was commented on. 
Once I commented out that part and ran it again, it showed a data map with a normal California map.
task 4
  # 1. Create input functions.
  training_input_fn = lambda: my_input_fn(training_examples, training_targets["median_house_value"], batch_size=batch_size)# YOUR CODE HERE
  predict_training_input_fn = lambda: my_input_fn(training_examples, training_targets["median_house_value"], num_epochs=1, shuffle=False)# YOUR CODE HERE
  predict_validation_input_fn = lambda: my_input_fn(validation_examples, validation_targets["median_house_value"], num_epochs=1, shuffle=False)# YOUR CODE HERE

  # 2. Take a break and compute predictions.
  training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn)
  training_predictions = np.array([item['predictions'][0] for item in training_predictions]) # YOUR CODE HERE
  validation_predictions = linear_regressor.predict(input_fn=predict_validation_input_fn)
  validation_predictions = np.array([item['predictions'][0] for item in validation_predictions]) # YOUR CODE HERE

linear_regressor = train_model(
    # TWEAK THESE VALUES TO SEE HOW MUCH YOU CAN IMPROVE THE RMSE
    learning_rate=0.00002,
    steps=500,
    batch_size=5,
    training_examples=training_examples,
    training_targets=training_targets,
    validation_examples=validation_examples,
    validation_targets=validation_targets)

Training model...
RMSE (on training data):
  period 00 : 213.83
  period 01 : 201.23
  period 02 : 190.77
  period 03 : 182.70
  period 04 : 174.81
  period 05 : 170.00
  period 06 : 165.97
  period 07 : 163.70
  period 08 : 162.12
  period 09 : 161.23
Model training finished.

task 5
california_housing_test_data = pd.read_csv("https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv", sep=",")
# YOUR CODE HERE
test_examples = preprocess_features(california_housing_test_data)
test_targets = preprocess_targets(california_housing_test_data)

predict_test_input_fn = lambda: my_input_fn(test_examples, test_targets["median_house_value"], num_epochs=1, shuffle=False)

test_predictions = linear_regressor.predict(input_fn=predict_test_input_fn)
test_predictions = np.array([item['predictions'][0] for item in test_predictions])
# Compute loss.
root_mean_squared_error = math.sqrt(
    metrics.mean_squared_error(test_predictions, test_targets))

print("Final RMSE (on test data): %0.2f" % root_mean_squared_error)

Final RMSE (on test data): 162.96
b. Give a one-paragraph summary of what you learned about using training, validation and testing datasets.
Splitting a data set into training, validation, and testing has an advantage in the workflow. 
This can greatly reduce the possibility of overfitting by evaluating a training set with a validation set and re-evaluating the result with a testing set. 
To configure the training and validation, data debugging is required to compare the correct data, and both sets must always be shuffled for data consistency.
